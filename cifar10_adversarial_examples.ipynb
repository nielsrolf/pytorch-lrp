{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Examples for cifar10\n",
    "\n",
    "The net is implemented in `utils` and taken from [https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-download-beginner-blitz-cifar10-tutorial-py](here). Some code is also taken from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some simple image visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from cifar10_utils import *\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's lode a network trained on cifar10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "second_net.load(\"cifar10net\")\n",
    "accuracy = second_net.accuracy(testloader)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can generate some adversarial examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def one_hot(labels):\n",
    "    return torch.from_numpy(np.eye(10)[labels]).float()\n",
    "\n",
    "def acc(outputs, labels):\n",
    "    return np.mean(outputs.detach().numpy().argmax(axis=1) == labels)\n",
    "\n",
    "def copy(images):\n",
    "     return torch.tensor(images, requires_grad=True)\n",
    "    \n",
    "def predicted(inputs):\n",
    "    return [classes[j] for j in net.forward(inputs).detach().numpy().argmax(axis=1)]\n",
    "    \n",
    "def plot_ae(images, adversarial):\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "    imshow(torchvision.utils.make_grid(images.detach()))\n",
    "    print('Predicted: ', predicted(images))\n",
    "    imshow(torchvision.utils.make_grid(adversarial.detach()))\n",
    "    imshow(torchvision.utils.make_grid((adversarial-images).detach()))\n",
    "    print('Predicted Adversarial: ', predicted(adversarial))\n",
    "    \n",
    "# Adversarial noise:\n",
    "def adversarial_noise(net, images, target_class, lr=0.01, plot_steps=False):\n",
    "    noise = torch.zeros_like(images)\n",
    "    outputs = net.forward(images)\n",
    "    N = images.shape[0]\n",
    "    target_classes = [target_class]*N\n",
    "    adversarial = copy(images)\n",
    "    adversarial.requires_grad_(True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD([adversarial], lr=lr, momentum=0.5)\n",
    "\n",
    "    print(\"Make everything a \", classes[target_class])\n",
    "\n",
    "    def step():\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net.forward(adversarial)\n",
    "        loss = criterion(outputs, torch.Tensor(target_classes).long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    applied = 0 \n",
    "    print(\"Initially:\")\n",
    "    plot_ae(images, adversarial)\n",
    "    while acc(net.forward(adversarial), target_classes)!=1:\n",
    "        step()\n",
    "        applied += 1\n",
    "        if applied % 100 == 0 and plot_steps:\n",
    "            print(\"Accuracy:\", acc(net.forward(adversarial), target_classes))\n",
    "            plot_ae(images, adversarial)\n",
    "    print(\"Finally:\")\n",
    "    print(\"Accuracy:\", acc(net.forward(adversarial), target_classes))\n",
    "    plot_ae(images, adversarial)\n",
    "    \n",
    "    return (adversarial - images).detach()\n",
    "\n",
    "images, labels = images, labels = dataiter.next()\n",
    "an = adversarial_noise(net, images, random.randint(0,9))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
