{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRP-gamma\n",
    "\n",
    "In this notebook, I try to implement LRP gamma without using gradients.\n",
    "\n",
    "The advantage of not using gradients is, that it is possible to compute gradients of functions that depend on heatmaps. Since pytorch does not allow to compute gradients of gradients, it's the only way to do it.\n",
    "\n",
    "`cifar10_utils.py` contains the net and dataloaders of the pytorch [https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-download-beginner-blitz-cifar10-tutorial-py](cifar10 tutorial). Additionally, it contains `input_times_gradient(net, images, target_pattern)` and `plot_heatmaps(images, heatmaps)`. The idea is to analyze their trained network using LRP-gamma.\n",
    "\n",
    "Let's prepare the implementation and load a trained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from cifar10_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5268\n",
      "Class Accuracy: {'plane': 0.5869017632241813, 'car': 0.7869674185463659, 'bird': 0.31690140845070425, 'cat': 0.2810126582278481, 'deer': 0.33164556962025316, 'dog': 0.5699208443271768, 'frog': 0.517162471395881, 'horse': 0.5382585751978892, 'ship': 0.7306733167082294, 'truck': 0.5280612244897959}\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load(\"cifar10net\")\n",
    "accuracy = net.accuracy(testloader)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Class Accuracy:\", net.class_accuracy(testloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be dealing with different heatmapping techniques. The functions that generate them have the regular name, and objects that contain heatmaps will be called `h_<shortname>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement deeptaylor.\n",
    "We need the forward activations, so let's rewrite the network class a bit.\n",
    "\n",
    "We want to add rules to layers that depend on their actications during the forwarding.\n",
    "So we wrap the forwarding and create a number of `ExplainableLayer`s. Then we create a class for models that support deep taylor decompositions.\n",
    "\n",
    "We can use it by subclassing from `ExplainableLayer` and adding the architecture there, like in the example `ExplainNet` which is a copy of `cifar10utils.Net`. But if we also want to use existing trained models, we can use `ExplainableLayer.from_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import copy\n",
    "import pdb\n",
    "\n",
    "na = None\n",
    "\n",
    "\n",
    "class ExplainableLayer():\n",
    "    \"\"\"\n",
    "    Base class for all layers that support deeptaylor\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def from_module(cls, src):\n",
    "        layer = copy.deepcopy(src)\n",
    "        layer.__class__ = cls\n",
    "        return layer\n",
    "\n",
    "\n",
    "class ReluLayer(ExplainableLayer, nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for layers that support Deep Taylor Decomposition\n",
    "    Saves the input, a and z\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.a = super().forward(x) # Super is called from a child class and via dependency injection this will be eg nn.Linear's forward layer \n",
    "        self.z = F.relu(self.a)\n",
    "        return self.z\n",
    "        \n",
    "    \n",
    "class Linear(ExplainableLayer, nn.Linear):\n",
    "    \"\"\"\n",
    "    For linear layers without Relu activation, usually the last\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        D = np.prod(x.shape[1:])\n",
    "        self.x = x\n",
    "        x = x.view(-1, D)\n",
    "        self.a = super().forward(x) # Super is called from a child class and via dependency injection this will be eg nn.Linear's forward layer \n",
    "        self.z = self.a\n",
    "        return self.z\n",
    "    \n",
    "    def zplus(self, R, eps=1e-9):\n",
    "        w_plus = F.relu(self.weight) # (D, d)\n",
    "        z_plus = F.linear(self.x, w_plus, None)\n",
    "        R_norm = R/(z_plus+eps) # (N, d)\n",
    "        return F.linear(R_norm, w_plus.transpose(0, 1))*self.x\n",
    "    \n",
    "    def zb(self, R, l, h, eps=1e-9):\n",
    "        w_plus  = F.relu(self.weight)\n",
    "        w_minus = -F.relu(-self.weight)\n",
    "        norm = self.z - l*F.linear(self.x, w_plus) - h*F.linear(self.x, w_minus)\n",
    "        R_norm = R/norm\n",
    "        return F.linear(R_norm, self.weight.transpose(0, 1))  \\\n",
    "            - l*F.linear(R_norm, self.w_plus.transpose(0, 1)) \\\n",
    "            - h*F.linear(R_norm, self.w_minus.transpose(0, 1))\n",
    "\n",
    "\n",
    "class LinearRelu(ReluLayer, Linear):\n",
    "    \"\"\"\n",
    "    Implements deep taylor rules for linear layers\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        D = np.prod(x.shape[1:])\n",
    "        return super().forward(x.view(-1, D))\n",
    "    \n",
    "    \n",
    "class ConvRelu(ReluLayer, nn.Conv2d):\n",
    "    \"\"\"\n",
    "    Implements deep taylor for conv2d layers\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv_args = {\n",
    "            'padding': self.padding,\n",
    "            'stride': self.stride\n",
    "        }\n",
    "        \n",
    "    def zplus(self, R, eps=1e-9):\n",
    "        w_plus = F.relu(self.weight) # (D, d)\n",
    "        z_plus = F.conv2d(self.x, w_plus, **self.conv_args)\n",
    "        R_norm = R/(z_plus+eps) # (N, d)\n",
    "        R_out_norm = F.conv_transpose2d(R_norm, w_plus, **self.conv_args)\n",
    "        return R_out_norm*self.x\n",
    "    \n",
    "    def zb(self, R, l, h, eps=1e-9):\n",
    "        w_plus  = F.relu(self.weight)\n",
    "        w_minus = -F.relu(-self.weight)\n",
    "        l = -F.relu(-self.z)\n",
    "        h = F.relu(self.z)\n",
    "        norm = self.z - F.conv2d(l, w_plus, **self.conv_args) \\\n",
    "                        - F.conv2d(h, w_minus, **self.conv_args)\n",
    "        R_norm = R/norm\n",
    "        return F.conv_transpose2d(R_norm, self.weight, **self.conv_args)  \\\n",
    "            - l*F.conv_transpose2d(R_norm, w_plus, **self.conv_args) \\\n",
    "            - h*F.conv_transpose2d(R_norm, w_minus, **self.conv_args)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_module(cls, src):\n",
    "        layer = copy.deepcopy(src)\n",
    "        layer.__class__ = cls\n",
    "        layer.conv_args = {\n",
    "            'padding': layer.padding,\n",
    "            'stride': layer.stride\n",
    "        }\n",
    "        return layer\n",
    "    \n",
    "\n",
    "class MaxPool(ReluLayer, nn.MaxPool2d):\n",
    "    \"\"\"\n",
    "    Maxpool2d layer with the interface of the explainable ReluLayer\n",
    "    \"\"\"\n",
    "    def get_flat_inverse(self):\n",
    "        \"\"\"\n",
    "        Returns a weight tensor that can be used to perform sum pooling or\n",
    "        deconvolution that distributes everything evenly among input cells\n",
    "        \"\"\"\n",
    "        if hasattr(self, '_flat_inverse'):\n",
    "            return self._flat_inverse\n",
    "        \n",
    "        if isinstance(self.kernel_size, int):\n",
    "            kernel_size = [self.kernel_size, self.kernel_size]\n",
    "        else:\n",
    "            kernel_size = list(self.kernel_size)\n",
    "        \n",
    "        num_channels = self.z.shape[1]\n",
    "        \n",
    "        weight = np.zeros([num_channels, num_channels]+kernel_size)\n",
    "        for c in range(num_channels):\n",
    "            weight[c,c] = 1/np.prod(kernel_size)\n",
    "        weight = torch.from_numpy(weight).float()\n",
    "        \n",
    "        self._flat_inverse = weight\n",
    "        return self._flat_inverse\n",
    "    \n",
    "    def zplus(self, R, eps=1e-9):\n",
    "        # distribute relevance flat to all input fields\n",
    "        weight = self.get_flat_inverse()\n",
    "        R_prop = F.conv_transpose2d(R, weight,\n",
    "                padding=self.padding, stride=self.stride)\n",
    "        return R_prop\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_module(src):\n",
    "        return MaxPool(kernel_size=src.kernel_size,\n",
    "                      stride=src.stride,\n",
    "                      padding=src.padding,\n",
    "                      dilation=src.dilation,\n",
    "                      return_indices=False,\n",
    "                      ceil_mode=src.ceil_mode\n",
    "                      )\n",
    "    \n",
    "    \n",
    "class ExplainableModel(TrainableNet):\n",
    "    \"\"\"\n",
    "    Base class for networks that implement deep taylor decomposition.\n",
    "    Network architecture is not specified here\n",
    "    \n",
    "    Subclasses can do some of the following:\n",
    "        - Add an architecture to `__init__`\n",
    "        - Overwride `deeptaylor,` if the architecture and input domains require a\n",
    "        different set of rules\n",
    "        - Overwride `from_model` if the architecture requires it.\n",
    "    \"\"\"\n",
    "    def __init__(self, layers, min_x=None, max_x=None):\n",
    "        \"\"\"\n",
    "        Layers: Instances of subclasses of ReluLayer\n",
    "        min_x, max_x: box constraints of the input domain, zB rule will be used there\n",
    "            if not set, ww rule will be used in the first layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        self.min_x, self.max_x = min_x, max_x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def layer_shapes(self, x):\n",
    "        print(x.shape)\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "            print(f\"({layer.__class__.__name__}) ->\", x.shape)\n",
    "        return x\n",
    "    \n",
    "    def deeptaylor(self, x, pattern):\n",
    "        \"\"\"\n",
    "        Deep Taylor Decomposition, where relevance is the outputlayer is predictions*pattern\n",
    "        Pattern: eg one_hot(labels) if the heatmap for the correct class should be used\n",
    "        \"\"\"\n",
    "        out = self.forward(x)\n",
    "        R = F.relu(out*pattern)\n",
    "        R_total = R.sum()\n",
    "        print(R.shape)\n",
    "        \n",
    "        def debug_info(layer, R):\n",
    "            print(f\"({layer.__class__.__name__}) ->\", R.shape)\n",
    "            print(f\"({layer.__class__.__name__})     Conservation error: {R.sum()/R_total}\")\n",
    "            if R.min() < 0:\n",
    "                print(f\"({layer.__class__.__name__})     encountered negative values\")\n",
    "            print(\"\")\n",
    "            \n",
    "        for layer in self.layers[1:][::-1]:\n",
    "            R = R.view(layer.z.shape)\n",
    "            R = layer.zplus(R)\n",
    "            debug_info(layer, R)\n",
    "            \n",
    "        # Select the input layer rule\n",
    "        if self.min_x is None and self.max_x is None:\n",
    "            R = self.layers[0].ww(R)\n",
    "        elif self.min_x == 0 and self.max_x is None:\n",
    "            R = self.layers[0].zplus(R)\n",
    "        else:\n",
    "            R = self.layers[0].zb(R, self.min_x, self.max_x)\n",
    "        debug_info(self.layers[0], R)\n",
    "        return R\n",
    "    \n",
    "    @classmethod\n",
    "    def from_model(cls, model, layer_names, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        model: nn.Module\n",
    "        layer_names: list[string] contains the property names of the mappings that define the network\n",
    "        eg: if model.forward does this:\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = x.view(-1, 16 * 5 * 5)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "        layer_names should look like this:\n",
    "        ['conv1', 'pool', 'conv2', 'pool', 'fc1', 'fc2', 'fc3']\n",
    "        \n",
    "        Relus don't have to be specified:\n",
    "            assumes that relus are used everywhere but in the last layer\n",
    "            assumes the last layer is linear\n",
    "        Reshaping does not have to be specified\n",
    "        \n",
    "        Relies on the fact that each ReluLayer is also subclass of the class of model\n",
    "        \"\"\"\n",
    "        def casted_layer(src, last_layer=False):\n",
    "            # finds the Explainable equivalent of src.__class__\n",
    "            if last_layer:\n",
    "                return Linear.from_module(src)\n",
    "            for layer_type in ReluLayer.__subclasses__():\n",
    "                if issubclass(layer_type, src.__class__):\n",
    "                    return layer_type.from_module(src)\n",
    "        \n",
    "        # cast all layers\n",
    "        # all but the last are casted to relu layers\n",
    "        layers = [casted_layer(model._modules[l]) for l in layer_names[:-1]] + \\\n",
    "                 [casted_layer(model._modules[layer_names[-1]], last_layer=True)]\n",
    "        \n",
    "        # now create a ExplainBase object which we call self, and pretend to be a constructor\n",
    "        self = cls(layers, *args, **kwargs)\n",
    "        # add the layers to the properties of self, in hope that \n",
    "        # pytorch transforms it to a self._modules element\n",
    "        for l, layer in zip(layer_names, layers):\n",
    "            self.__dict__[l] = layer\n",
    "            \n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the from_model works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5268\n",
      "Class Accuracy: {'plane': 0.5869017632241813, 'car': 0.7869674185463659, 'bird': 0.31690140845070425, 'cat': 0.2810126582278481, 'deer': 0.33164556962025316, 'dog': 0.5699208443271768, 'frog': 0.517162471395881, 'horse': 0.5382585751978892, 'ship': 0.7306733167082294, 'truck': 0.5280612244897959}\n"
     ]
    }
   ],
   "source": [
    "enet = ExplainableModel.from_model(net, ['conv1', 'pool', 'conv2', 'pool', 'fc1', 'fc2', 'fc3'])\n",
    "accuracy = enet.accuracy(testloader)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Class Accuracy:\", net.class_accuracy(testloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!\n",
    "\n",
    "Now, let's alsp generate some heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "(Linear) -> torch.Size([10, 84])\n",
      "(Linear)     Conservation error: 1.0\n",
      "\n",
      "(LinearRelu) -> torch.Size([10, 120])\n",
      "(LinearRelu)     Conservation error: 1.0000001192092896\n",
      "\n",
      "(LinearRelu) -> torch.Size([10, 400])\n",
      "(LinearRelu)     Conservation error: 1.0000001192092896\n",
      "\n",
      "(MaxPool) -> torch.Size([10, 16, 10, 10])\n",
      "(MaxPool)     Conservation error: 1.0\n",
      "\n",
      "(ConvRelu) -> torch.Size([10, 6, 14, 14])\n",
      "(ConvRelu)     Conservation error: 0.9999998807907104\n",
      "\n",
      "(MaxPool) -> torch.Size([10, 6, 28, 28])\n",
      "(MaxPool)     Conservation error: 1.000000238418579\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [6, 3, 5, 5], expected input[10, 6, 28, 28] to have 3 channels, but got 6 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-fe5bc5f69535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mh_dtd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeeptaylor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplot_heatmaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_dtd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-b2aa52783286>\u001b[0m in \u001b[0;36mdeeptaylor\u001b[0;34m(self, x, pattern)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzplus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0mdebug_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-b2aa52783286>\u001b[0m in \u001b[0;36mzb\u001b[0;34m(self, R, l, h, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_plus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                         \u001b[0;34m-\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_minus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mR_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_transpose2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [6, 3, 5, 5], expected input[10, 6, 28, 28] to have 3 channels, but got 6 channels instead"
     ]
    }
   ],
   "source": [
    "enet = ExplainableModel.from_model(\n",
    "    net,\n",
    "    ['conv1', 'pool', 'conv2', 'pool', 'fc1', 'fc2', 'fc3'],\n",
    "    min_x=-1, max_x=1\n",
    ")\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "h_dtd = enet.deeptaylor(images, one_hot(labels))\n",
    "plot_heatmaps(images, h_dtd.sum(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is an example how to rebuild Net directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "   \n",
    "class ExplainNet(ExplainableModel):\n",
    "    \"\"\"\n",
    "    Rebuilt of cifar10utils.Net with deep taylor support\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        layers = [\n",
    "            ConvRelu(3, 6, 5),\n",
    "            MaxPool(2, 2),\n",
    "            ConvRelu(6, 16, 5),\n",
    "            MaxPool(2, 2),\n",
    "            LinearRelu(16 * 5 * 5, 120),\n",
    "            LinearRelu(120, 84),\n",
    "            LinearRelu(84, 10)\n",
    "        ]\n",
    "        super().__init__(layers, -1, 1)\n",
    "        \n",
    "        # Because pytorch is weird, the submodels cannot be stored in a list\n",
    "        self.l1 = layers[0]\n",
    "        self.l2 = layers[1]\n",
    "        self.l3 = layers[2]\n",
    "        self.l4 = layers[3]\n",
    "        self.l5 = layers[4]\n",
    "        self.l6 = layers[5]\n",
    "            \n",
    "        \n",
    "\n",
    "enet_sister = ExplainNet()\n",
    "enet_sister.train(1, trainloader)\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "h_dtd = enet_sister.deeptaylor(images, one_hot(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#issubclass(enet.layers[1].__class__ , nn.MaxPool2d)\n",
    "#help(nn.Conv2d)\n",
    "net.conv1.weight.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
