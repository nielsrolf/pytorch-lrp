{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#LayerizedNet-Tutorial\" data-toc-modified-id=\"LayerizedNet-Tutorial-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span><code>LayerizedNet</code> Tutorial</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-layers-with-extra-logic\" data-toc-modified-id=\"Create-layers-with-extra-logic-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Create layers with extra logic</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `LayerizedNet` Tutorial\n",
    "\n",
    "For many experiments, it is useful to have an explicit layerized version of your model.\n",
    "You can do this by creating your network class directly like this, but then you can't use your new implemented functionality with pretrained models. `LayerizedNet` is a class that builds a copy of an existing framework into a network that is explicitly layerized, i.e. has a `layers` attribute, into a set of layers you define.\n",
    "\n",
    "The functionality of layers can be plugged using multiple inheritance. This makes usage of `super()`s method resolution order. If you not familiar with it, it may be helpful to google it. The most important thing to note is, that `super()` does not always call the parent class of the class where it is used in the code: if an object of class `C(A, B)` calls `super()`, it looks for the method in class `A`. If this method uses `super()` itself, it looks for the method in class `B` before it looks for the mathod in the parent class of `A`.\n",
    "\n",
    "Also important is `LayerizedNet.from_model`. It takes an existing model `model`, a list `layer_namess` of the names of the submodules that correspond to the layers, and two layer classes: the first one, `layer_base_type`, is the parent class for all layers except the last one, and the second one, `last_layer_type`, is the class of the last layer. The reason for this is, that it makes it very convenient to layerize models that use a certain nonlinear activation function in all but the last layer.\n",
    "\n",
    "The method definition looks like this:\n",
    "```Python\n",
    "@classmethod\n",
    "def from_model(cls, model, layer_names, layer_base_type, last_layer_type, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    model: nn.Module\n",
    "    layer_names: list[string] contains the property names of the mappings that define the network\n",
    "        eg: if model.forward does this:\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = x.view(-1, 16 * 5 * 5)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "        layer_names should look like this:\n",
    "        ['conv1', 'pool', 'conv2', 'pool', 'fc1', 'fc2', 'fc3']\n",
    "    layer_base_type: looks for layer classes that subclass this type to convert the model\n",
    "    last_layer_type: type of the last layer\n",
    "    *args, **kwargs: will be passed to the constructor of `cls`, i.e. LayerizedNet or a subclass\n",
    "\n",
    "    Nonlinearities don't have to be specified if they are implemented in layer_base_type.\n",
    "    Alternatively, they can be treated as extra layers.\n",
    "    Reshaping should be implemented by the layer's .forward()\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "## Create layers with extra logic\n",
    "Let's load the `cifar10_utils` net so that we can create a layer scheme and a network class that adds some custom code that can make use of the layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Accuracy: 0.5268\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from cifar10_utils import *\n",
    "net = Net()\n",
    "net.load(\"cifar10net\")\n",
    "accuracy = net.accuracy(testloader)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a base layer and subclass from it, but also from the class that is imitated. For example, if the original network uses a `nn.Linear` module, `LayerizedNet.from_model` looks for a class that is both subclass of our custom `layer_base_type` and `nn.Linear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5268\n"
     ]
    }
   ],
   "source": [
    "from layerized_net import *\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class AMLayer(Layer):\n",
    "    def custom_code(self, X):\n",
    "        # add your additional code here, or overwride forward\n",
    "        pass\n",
    "   \n",
    "class Relu():\n",
    "    def forward(self, x):\n",
    "        return F.relu(super().forward(x))\n",
    "    \n",
    "class Linear(AMLayer, nn.Linear):\n",
    "    \"\"\"\n",
    "    For linear layers without Relu activation, usually the last\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        D = np.prod(x.shape[1:])\n",
    "        x = x.view(-1, D)\n",
    "        return super().forward(x)\n",
    "\n",
    "class LinearRelu(Relu, Linear):\n",
    "    pass\n",
    "\n",
    "class ConvRelu(AMLayer, Relu, nn.Conv2d):\n",
    "    pass\n",
    "\n",
    "class MaxPool(AMLayer, Relu, nn.MaxPool2d):\n",
    "    pass\n",
    "\n",
    "class AMNet(LayerizedNet):\n",
    "    def activation_maximization(self, layer, pattern):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "layerized_net = AMNet.from_model(\n",
    "    model=net,\n",
    "    layer_names=['conv1', 'pool', 'conv2', 'pool', 'fc1', 'fc2', 'fc3'],\n",
    "    layer_base_type=Relu, last_layer_type=Linear)\n",
    "\n",
    "accuracy = layerized_net.accuracy(testloader)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it, it worked!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
